---
title: "Validation Checks for US SMH files"
output: 
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Validation Checks}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The main functions in the `SMHvalidation` R package aim to validate and 
visualize Scenario Modeling Hub submissions.

For more information on the Scenario Modeling Hub and on how to
participate, please feel free to consult the 
[Scenario Modeling Hub website](https://scenariomodelinghub.org).

## Validation on model projection

*Remarks:* Starting January 2025, the SMHvalidation package format
and associated JSON file format has been updated to follow the
[Hubverse](https://hubdocs.readthedocs.io/en/latest/) schema v5 format.
This documentation is about the last version of the data.

For previous versions of the documentation, please consult
past version of the package.

### `Validate_submission()` function

```{r setup}
library(SMHvalidation)
```

#### Input

The `validate_submission()` function requires two parameters:

-   `path`: path to the submission file (or folder for partitioned data) 
    to test. PQT, PARQUET, CSV, ZIP (not partitioned), or GZ (not partitioned) 
    file formats are accepted. The path should be relative to the path of the hub
    containing the file to check.
-   `hub_path`:  path to the hub containing the submission file. The hub should
    follow the hubverse standard and organization. For more information on 
    hubverse, please consult the 
    [associated website](https://hubverse.io/en/latest/user-guide/hub-structure.html).
    
For more information on this function, please consult the associated
documentation at `?validate_submission()`

The package contains an example hub with two example sumbission that can be 
used to test the function. There paths can be accessed by using the 
`system.file()` function.     
```{r setup_path}
hub_path <- system.file("extdata/exp/", package = "SMHvalidation")
```

The example hub follows the hubverse standard and organization. For more 
information on hubverse, please consult the 
[associated website](https://hubverse.io/en/latest/user-guide/hub-structure.html).

It contains example submission for two teams, one partitioned. 
```{r setup_path_f}
path_1 <- "team2-modelb/2023-11-12-team2-modelb.parquet"
path_2 <- "t3-mc"
```

##### Sample - Output type format

In the Scenario Modeling Hub file format two possible formats are used for the
`"sample"` output type:

(1) All the submissions for a specific round should follow the same format 
with predefined `output_type_id` column content. 

(2) For a specific round, the hub collects the sample "pairing" (or
joint distribution) information each team uses to generate the trajectories. In
this case, the `output_type_id` column is set to `"NA"` for the `"sample"` 
output type and the "pairing" information is collected into two columns: 
`"run_grouping"` and `"stochastic_run"`. For more information on this format,
please consult the 
[SMH Sample format documentation](https://scenariomodelinghub.org/documentation/sample_format.html) 

For option (2), the optional parameter `merge_sample_col` cam be used to
indicate the additional columns used to set the the sample ID information, for 
example: `⁠c("run_grouping" and "stochastic_run")⁠`
        
##### Partitioned files:

If the submission files is in a "partitioned" format,  the `path` parameter 
should be to a directory to a folder containing **ONLY** the "partitioned" 
files. If any other file is present in the  directory, it will be included in 
the validation.

Example:
```{r test2}
validate_submission(path_2, hub_path,
                    partition = c("origin_date", "target"),
                    merge_sample_col = c("run_grouping", "stochastic_run"))
```

If the `path` folder contains multiple rounds, please use the `round_id` 
parameter to signal which round to test.

```{r test2b}
validate_submission(path_2, hub_path,
                    partition = c("origin_date", "target"),
                    merge_sample_col = c("run_grouping", "stochastic_run"),
                    round_id = "2023-11-12")
```

#### Output

The function returns multiple messages and if any issue a failure or 
an error message.

-   if the check succeeds: a message is returned
-   if the check fails: an error or a failure message is returned. A failure 
    represents a check that fails but does not block the proceeding of the 
    validation to other checks. Whereas an error, will stop the validation 
    process. 
    
Example:
```{r test1}
validate_submission(path_1, hub_path)
```

    
#### Submission File Tests

-   The `round_id` information, either the date extracted in the file name(s) 
    (`path`) or via the `round_id` parameter, should match one of the
    `round_id` in the associated `tasks.json` file.

-  The submission file(s) should be in one of the accepted formats:
   - Parquet file (preferred): `.parquet` or `.gz.parquet`. Partitioning in
   this format is also accepted. 
   - CSV file: `.csv`. Partitioning in this format is also accepted. 
   - Compressed format: `.gz` or `.zip`
   
-  All columns containing `date` should contain date information in the 
   "YYYY-MM_DD" format.
   
-  No column should be in a "factor" format.

##### Columns format

The name and number of the columns are corresponding to the expected
format, for example:

|origin_date|scenario_id|target|horizon|location|output_type|output_type_id|value|
|:-----:|:-----:|:----:|:----:|:----:|:---:|:---:|:---:|
|||||||||

or 

|origin_date|scenario_id|target|horizon|location|output_type|output_type_id|run_grouping|stochastic_run|value|
|:-----:|:-----:|:----:|:----:|:----:|:---:|:---:|:---:|:---:|:---:|
|||||||||||

The order of the column is not important but the submission file
should contain the expected number of columns with each name
correctly spelled.

However, the format type of each columns should match the expected format
as described in the `tasks.json`.

*Remarks:* In this example, the `task_ids` values correspond to:
origin_date, scenario_id, target, horizon, location.

*Remarks:* If one required column is missing, the submission test will
directly stop and return an error message without running all the others
tests.

##### Round ID and `"origin_date"` 

-   The `origin_date` column contains:
    -   one unique date value in the `YYYY-MM-DD` format
    -   the column should contain information in "character" or "Date" format

If the `origin_date` is also the round ID, the `origin_date` and round ID (date)
in the file path should correspond.

*Remarks:* Implemented since January 2022, all submissions previous to
this date can have a slightly more flexible date information.

##### Required values/variables

-   Each of the task id columns values correspond to the expected ID of the
    expected round without any spelling errors.
    
-   Each task_id/output_type/output type ID group combination has one unique 
    value projected.
    For example: only 1 value associated with: quantile `0.5`, location `US`,
    target `inc hosp`, horizon `1` and, scenario `A`. 
    
-   The projection contains the expected value (for example, integer
    value `>= 0` or numeric in between 0 and 1). `NA` value are not accepted
    
-   The submission file contains projections for all the required
    targets. **The submission file might be accepted if some targets are
    missing, but might return an error message and the submission might
    not be included in the Ensembles**
    
-   For some targets, for example `peak size hosp`, no `"horizon"` information
    is expected. In this case, the column `"horizon"` should be set to `NA`
    
##### Output type / output type ID

-   The column `output_type_id` (or `run_grouping` and `stochastic_run`) for 
    the output type `"sample"` should only contain integer values.
    
-   The submission should contain the expected number of trajectories for each
    task_id group, as indicated in the associated JSON file (`js_def` parameter).
    And each group should contain the same number of trajectories.
    
-   If the submission expected pairing samples, the pairing information is 
    extracted from the `"compound_taskid_set"` information in the associated 
    `tasks.json` file. The minimal pairing is expected, but additional pairing
    is accepted. 
    For more information on pairing or grouping information, please consult the
[SMH Sample format documentation](https://scenariomodelinghub.org/documentation/sample_format.html).
    The hubverse is defining the pairing information in a different way, with
    a different vocabulary, for more information on the hubverse version, please
    consult the [Sample output type and Compound modeling tasks](https://hubverse.io/en/latest/user-guide/sample-output-type.html) 
    information.

-   If the submission file contains quantilesm, the value for each group should ncrease with the quantiles.
    For example, for the 1st week ahead of target X for the location Y and for
    the scenario A, if quantile `0.01`= `5` than quantile `0.5` should be equal
    or greater than `5`
    
##### Additional tests

-   The locations  correspond to the location name as expressed in the
    associated metadata JSON file (`js_def` parameter). If FIPS codes are
    expected and if the FIPS numbers are missing a trailing zero,
    the submission will be accepted but a warning message will be returned.
    
*Remarks:* If a submission file contains only state level projection
(one or multiple), the `location` column might be automatically identified
as numeric even if it was submitted in a character format. In this case,
a warning message will be automatically printed on the validation but that warning can be safely ignored. 

-   For each unique task_id group, excluding horizon information and except
    locations: `66` (Guam), `69` (Northern Mariana Island), `60`
    (American Samoa), `74` (US. Minor Outlying Islands), the whole
    projection does not contain only 1 unique value. For example, the
    projection for the incidence cases for one location and for one
    scenario does not contain only one unique value for the whole time
    series. **As there is a possibility that 0 deaths or cases might be
    projected, the submission will still be accepted if the test failed
    but it will return a failure message asking to verify the
    projection**
    
-   For the cumulative targets, for example `cum hosp`, for each task_id 
    and output_type group (excluding `"horizon"`), the value is not decreasing
    with time. 

-   [optional] Each projected value cannot by greater than the population size
    of the corresponding geographical entity. This test is run only if the `pop_path`
    parameter is not set to `NULL`. **As an individual can be reinfected, the
    submission will still be accepted if the test failed but it will return a
    warning message asking to verify the projection**.

-   [optional] For the cumulative cases and deaths projection, the projected
    value should not be less than the week 0 (or week -1, depending on the
    availability on the time of submission) of the observed cumulative
    cases and deaths, respectively. The test allow a difference of 5% to
    take into account the difference between time of pulling the
    observed data, sources, ... (only tested if the `target-data` parameter
    is not `NULL` and contains observed cumulative cases and deaths
    value).
    
-   [optional] The number of decimal points accepted in the column `"value"` is
    lower or equivalent to the parameter `n_decimal` (only run if `n_decimal`
    is not set to `NULL`).

### Submission file path

If the file is not partitioned, the hubValidations `validate_model_file()` will
be used to check:

-  the file is in the expected folder with the expected file name
-  only one file per round is submitted
-  associated metadata file is present in the hub

```{r}
hubValidations::validate_model_file(hub_path, path_1)
```

For more information on `validate_model_file()`, please consult the associated
help page: `?validate_model_file`

If the file is partitioned, the SMHvalidation package contains a wrapper 
function based on hubValidations `validate_model_file()`. 

The function `validate_part_file()` required three parameters:

-   `hub_path`: path to the repository containing the submission files and
    the `tasks.json` file, in the hubverse format.
-   `folder_path`: path to the folder containing only one round specific 
    partitioned submission files. The folder is expected to be situated in the 
    `model-output` folder  and the path here should be relative to the
    `hub_path`, model output folder.
-   `partition`: character vector corresponding to the column names of each
    path segments.

For example:

```{r}
SMHvalidation::validate_part_file(hub_path, path_2, c("origin_date", "target"))
```

or 

```{r}
SMHvalidation::validate_part_file(hub_path, "t3-mc/2023-11-12/", c("target"))
```

The wrapper can also be used on non partitioned files, the `partition` partition
just need to be set to `NULL`, only in the case the folder contains only one 
round specific file. 

```{r}
SMHvalidation::validate_part_file(hub_path, "team2-modelb/", NULL)
```

## Validation on Metadata and Abstract

For the metadata file, the hubValidations `validate_model_metadata()` will
be used to validate it:

```{r}
hubValidations::validate_model_metadata(hub_path, "team2-modelb.yaml")
```

The validation for the "abstract" files associated with the submission is 
currently manual.
